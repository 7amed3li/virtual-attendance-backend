// clean_duplicates.js - Duplicate yoklama kayÄ±tlarÄ±nÄ± temizle
const { Pool } = require('pg');
require('dotenv').config();

const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false
});

async function cleanDuplicates() {
  console.log('ğŸ§¹ Duplicate yoklama kayÄ±tlarÄ± temizleniyor...\n');
  
  const client = await pool.connect();
  try {
    await client.query('BEGIN');
    
    // 1. Ã–nce mevcut duplicate kayÄ±tlarÄ± listele
    console.log('ğŸ“‹ Mevcut duplicate kayÄ±tlar:');
    const duplicates = await client.query(`
      SELECT oturum_id, ogrenci_id, COUNT(*) as kayit_sayisi, 
             array_agg(id ORDER BY id) as id_listesi,
             array_agg(count ORDER BY id) as count_listesi
      FROM yoklamalar 
      WHERE tur_no IS NULL 
      GROUP BY oturum_id, ogrenci_id 
      HAVING COUNT(*) > 1
      ORDER BY oturum_id, ogrenci_id
    `);
    
    console.log(`Toplam ${duplicates.rows.length} adet duplicate grup bulundu:`);
    duplicates.rows.forEach((row, index) => {
      console.log(`${index + 1}. Oturum: ${row.oturum_id}, Ã–ÄŸrenci: ${row.ogrenci_id}, KayÄ±t SayÄ±sÄ±: ${row.kayit_sayisi}`);
      console.log(`   ID'ler: [${row.id_listesi.join(', ')}], Count'lar: [${row.count_listesi.join(', ')}]`);
    });
    
    // 2. Her duplicate grup iÃ§in, en yÃ¼ksek count'a sahip kaydÄ± tut, diÄŸerlerini sil
    let totalDeleted = 0;
    
    for (const row of duplicates.rows) {
      const ids = row.id_listesi;
      const counts = row.count_listesi;
      
      // En yÃ¼ksek count'a sahip kaydÄ± bul
      let maxCount = Math.max(...counts);
      let maxCountIndex = counts.indexOf(maxCount);
      let keepId = ids[maxCountIndex];
      
      // Silinecek ID'leri bul (tutulacak kayÄ±t hariÃ§)
      const deleteIds = ids.filter(id => id !== keepId);
      
      console.log(`\nğŸ”„ Oturum ${row.oturum_id}, Ã–ÄŸrenci ${row.ogrenci_id}:`);
      console.log(`   Tutulan kayÄ±t: ID ${keepId} (count: ${maxCount})`);
      console.log(`   Silinen kayÄ±tlar: [${deleteIds.join(', ')}]`);
      
      // Silinecek kayÄ±tlarÄ± sil
      if (deleteIds.length > 0) {
        const deleteResult = await client.query(
          'DELETE FROM yoklamalar WHERE id = ANY($1) RETURNING id',
          [deleteIds]
        );
        totalDeleted += deleteResult.rows.length;
        
        // Tutulan kaydÄ±n count'Ä±nÄ± gÃ¼ncellemek istiyorsanÄ±z:
        // await client.query(
        //   'UPDATE yoklamalar SET count = $1 WHERE id = $2',
        //   [maxCount, keepId]
        // );
      }
    }
    
    // 3. Temizlik sonrasÄ± kontrol
    console.log(`\nâœ… Toplam ${totalDeleted} adet duplicate kayÄ±t silindi`);
    
    const finalCheck = await client.query(`
      SELECT oturum_id, ogrenci_id, COUNT(*) as kayit_sayisi
      FROM yoklamalar 
      WHERE tur_no IS NULL 
      GROUP BY oturum_id, ogrenci_id 
      HAVING COUNT(*) > 1
    `);
    
    if (finalCheck.rows.length === 0) {
      console.log('ğŸ‰ TÃ¼m duplicate kayÄ±tlar baÅŸarÄ±yla temizlendi!');
    } else {
      console.log(`âš ï¸ Hala ${finalCheck.rows.length} adet duplicate grup var`);
    }
    
    await client.query('COMMIT');
    console.log('\nğŸ’¾ DeÄŸiÅŸiklikler kaydedildi');
    
  } catch (error) {
    await client.query('ROLLBACK');
    console.error('âŒ Hata:', error.message);
  } finally {
    client.release();
    await pool.end();
  }
}

// Script'i Ã§alÄ±ÅŸtÄ±r
if (require.main === module) {
  cleanDuplicates();
}

module.exports = { cleanDuplicates }; 